# overlay_app.py
import pandas as pd
import streamlit as st
import plotly.express as px
from datetime import date

# --- âš™ï¸ íŒŒì¼ ê²½ë¡œ (ìƒëŒ€ ê²½ë¡œ ì‚¬ìš© ê¶Œì¥) ---
PATH_RAW_SENSOR = "/Users/t2023-m0056/Desktop/íŒŒì¼/df_sensor.csv"
PATH_THRESHOLDS = "/Users/t2023-m0056/Desktop/íŒŒì¼/df_thresh_z (1).csv"
PATH_GROUND_TRUTH = "ground_truth_for_app.csv"
PATH_PRED_LGBM = "pred_lot.csv"
PATH_PRED_VARIANCE = "pred_variance.csv"

st.set_page_config(
    page_title="Sensor Overlay Dashboard",
    layout="wide",
    initial_sidebar_state="collapsed",
)

# [ìˆ˜ì •] ëŒ€ì‹œë³´ë“œ ì œëª©
st.title("ğŸ“Š Sensor Overlay Dashboard")

st.markdown(
    """<style>
[data-testid="stAppViewContainer"] .main .block-container {padding:1rem 1rem 0rem 1rem;}
[data-testid="stHeader"]{display:none;} footer{visibility:hidden;}
</style>""",
    unsafe_allow_html=True,
)


# --- ë°ì´í„° ë¡œë”© í•¨ìˆ˜ë“¤ ---
@st.cache_data
def load_raw():
    df = pd.read_csv(PATH_RAW_SENSOR)
    df["DateTime"] = pd.to_datetime(df["DateTime"], errors="coerce")
    return df.dropna(subset=["DateTime"]).sort_values("DateTime")


@st.cache_data
def load_thresholds():
    df = pd.read_csv(PATH_THRESHOLDS)
    df["ClusterLabel"] = pd.to_numeric(df["ClusterLabel"], errors="coerce").astype(
        "Int64"
    )
    df["ì„ê³„ê°’"] = pd.to_numeric(df["ì„ê³„ê°’"], errors="coerce")
    return df


@st.cache_data
def load_preds():
    frames = []
    try:
        a = pd.read_csv(PATH_PRED_LGBM)
        a["Source"] = "lgbm"
        a["PredCluster"] = (
            pd.to_numeric(a["PredCluster"], errors="coerce").fillna(0).astype(int)
        )
        a["VarianceRuleTriggers"] = ""
        frames.append(a)
    except FileNotFoundError:
        st.warning(
            f"{PATH_PRED_LGBM} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. lgbm.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ì˜ˆì¸¡ íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”."
        )
    try:
        b = pd.read_csv(PATH_PRED_VARIANCE)
        b["Source"] = "variance"
        b["PredCluster"] = (
            pd.to_numeric(b["PredCluster"], errors="coerce").fillna(0).astype(int)
        )
        if "VarianceRuleTriggers" not in b.columns:
            b["VarianceRuleTriggers"] = ""
        frames.append(b)
    except FileNotFoundError:
        st.warning(
            f"{PATH_PRED_VARIANCE} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. variance.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ì˜ˆì¸¡ íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”."
        )

    if not frames:
        return pd.DataFrame(
            columns=["Date", "Lot", "PredCluster", "VarianceRuleTriggers", "Source"]
        )

    pred_all = pd.concat(frames, ignore_index=True)
    pred_all["TriggersList"] = (
        pred_all["VarianceRuleTriggers"]
        .fillna("")
        .astype(str)
        .str.split(",")
        .apply(lambda L: [s.strip() for s in L if s and s.strip()])
    )
    return pred_all


@st.cache_data
def load_ground_truth():
    try:
        df = pd.read_csv(PATH_GROUND_TRUTH)
        return df
    except FileNotFoundError:
        st.error(
            f"ì •ë‹µ íŒŒì¼({PATH_GROUND_TRUTH})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. lgbm.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”."
        )
        return pd.DataFrame(columns=["Date", "Lot", "ClusterLabel"])


# --- ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ---
raw = load_raw()
pred = load_preds()
thr = load_thresholds()
truth = load_ground_truth()

# í‚¤ ì •ê·œí™”
raw["Date"] = pd.to_datetime(raw["Date"], errors="coerce").dt.date
pred["Date"] = pd.to_datetime(pred["Date"], errors="coerce").dt.date
truth["Date"] = pd.to_datetime(truth["Date"], errors="coerce").dt.date
raw["Lot"] = raw["Lot"].astype(str)
pred["Lot"] = pred["Lot"].astype(str)
truth["Lot"] = truth["Lot"].astype(str)

lot_span = (
    raw.groupby(["Date", "Lot"])["DateTime"].agg(start="min", end="max").reset_index()
)

# --- UI ì˜ì—­ ---
c1, c2 = st.columns([1, 1])
with c1:
    mode = st.selectbox("ê¸°ê°„ ëª¨ë“œ", ["ì „ì²´", "ê¸°ê°„ì„ íƒ"], index=0, key="date_mode")
    limit_start, limit_end = raw["DateTime"].min().date(), raw["DateTime"].max().date()

    if mode == "ê¸°ê°„ì„ íƒ":
        sel_range = st.date_input(
            "ê¸°ê°„ ì„ íƒ",
            value=(limit_start, limit_end),
            min_value=limit_start,
            max_value=limit_end,
            format="YYYY-MM-DD",
        )
        try:
            start_d, end_d = sel_range
        except ValueError:
            start_d, end_d = limit_start, limit_end
    else:
        start_d, end_d = limit_start, limit_end

with c2:
    kind = st.selectbox(
        "ë¶ˆëŸ‰ ìœ í˜•", ["ì „ì²´", "ë¶ˆëŸ‰ ìœ í˜• 1", "ë¶ˆëŸ‰ ìœ í˜• 2", "ë¶ˆëŸ‰ ìœ í˜• 3"], index=0
    )

cluster_map = {
    "ì „ì²´": [1, 2, 3],
    "ë¶ˆëŸ‰ ìœ í˜• 1": [1],
    "ë¶ˆëŸ‰ ìœ í˜• 2": [2],
    "ë¶ˆëŸ‰ ìœ í˜• 3": [3],
}
clusters = cluster_map[kind]
thr_cluster = clusters[0] if len(clusters) == 1 else None

# --- ë°ì´í„° í•„í„°ë§ ---
date_filter = (raw["DateTime"].dt.date >= start_d) & (raw["DateTime"].dt.date <= end_d)
base = raw[date_filter].copy()

pred_filtered = pred[pred["Date"].between(start_d, end_d)]
bad_span = lot_span.merge(pred_filtered, on=["Date", "Lot"], how="inner")
bad_span = bad_span[bad_span["PredCluster"].isin(clusters)]
bad_span_var = bad_span[bad_span["Source"] == "variance"].copy()
bad_span_lgbm = bad_span[bad_span["Source"] == "lgbm"].copy()

# --- ìƒíƒœ ê´€ë¦¬ ---
if "selected_point" not in st.session_state:
    st.session_state["selected_point"] = None


def clear_selection():
    st.session_state["selected_point"] = None


plot_cols_map = {
    "ì „ì²´": ["pH_std6", "Resistance_std6", "Resistance_ma6", "Power_std6"],
    "ë¶ˆëŸ‰ ìœ í˜• 1": ["pH_std6", "Resistance_std6"],
    "ë¶ˆëŸ‰ ìœ í˜• 2": ["Resistance_ma6"],
    "ë¶ˆëŸ‰ ìœ í˜• 3": ["pH_std6", "Power_std6"],
}
ycols = plot_cols_map[kind]

# --- ë ˆì´ì•„ì›ƒ ---
left, right = st.columns([5, 2], gap="small")

with left:
    if base.empty:
        st.warning("ì„ íƒ êµ¬ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        base["LotNum"] = pd.to_numeric(base["Lot"], errors="coerce")
        base = base.dropna(subset=["LotNum"])
        base["LotNum"] = base["LotNum"].astype(int)
        base = base[(base["LotNum"] >= 1) & (base["LotNum"] <= 22)]

        span = (
            base.groupby(["Date", "Lot"], as_index=False)["DateTime"]
            .agg(start="min", end="max")
            .assign(mid=lambda d: d["start"] + (d["end"] - d["start"]) / 2)
        )

        for col in ycols:
            agg_val = (
                base.groupby(["Date", "Lot"], as_index=False)[col]
                .mean()
                .rename(columns={col: "Value"})
            )
            agg = agg_val.merge(span, on=["Date", "Lot"], how="left").sort_values("mid")

            # [ìˆ˜ì •] ë¼ì¸ ê·¸ë˜í”„ ìƒì„± (x="mid" ì‚¬ìš©)
            fig = px.line(agg, x="mid", y="Value", title=col)

            for _, r in bad_span.iterrows():
                fig.add_vrect(
                    x0=r["start"],
                    x1=r["end"],
                    fillcolor="red",
                    opacity=0.1,
                    line_width=0,
                )

            # LGBM ì˜ˆì¸¡ ì  ì¶”ê°€
            if not bad_span_lgbm.empty:
                pts_lgbm = bad_span_lgbm.merge(agg, on=["Date", "Lot"], how="inner")
                if not pts_lgbm.empty:
                    pts_lgbm["Triggers"] = ""
                    fig.add_scatter(
                        x=pts_lgbm["mid"],
                        y=pts_lgbm["Value"],
                        mode="markers",
                        name="LGBM Prediction",
                        marker=dict(
                            size=12, symbol="x", color="red", line=dict(width=2)
                        ),
                        customdata=pts_lgbm[
                            [
                                "Date",
                                "Lot",
                                "PredCluster",
                                "Source",
                                "Triggers",
                                "Value",
                                "mid",
                            ]
                        ]
                        .astype(str)
                        .values,
                        hovertemplate="<b>%{customdata[3]} Prediction</b><br>"
                        + "Date: %{customdata[0]}<br>"
                        + "Lot: %{customdata[1]}<br>"
                        + "Value: %{customdata[5]}<extra></extra>",
                    )

            # Variance ì˜ˆì¸¡ ì  ì¶”ê°€
            if not bad_span_var.empty:
                var_lot = bad_span_var[
                    bad_span_var["TriggersList"].apply(lambda L: col in L)
                ]
                pts_var = var_lot.merge(agg, on=["Date", "Lot"], how="inner")
                if not pts_var.empty:
                    pts_var = pts_var.rename(
                        columns={"VarianceRuleTriggers": "Triggers"}
                    )
                    fig.add_scatter(
                        x=pts_var["mid"],
                        y=pts_var["Value"],
                        mode="markers",
                        name="Variance Prediction",
                        marker=dict(
                            size=12, symbol="circle", color="blue", line=dict(width=2)
                        ),
                        customdata=pts_var[
                            [
                                "Date",
                                "Lot",
                                "PredCluster",
                                "Source",
                                "Triggers",
                                "Value",
                                "mid",
                            ]
                        ]
                        .astype(str)
                        .values,
                        hovertemplate="<b>%{customdata[3]} Prediction</b><br>"
                        + "Date: %{customdata[0]}<br>"
                        + "Lot: %{customdata[1]}<br>"
                        + "Triggers: %{customdata[4]}<br>"
                        + "Value: %{customdata[5]}<extra></extra>",
                    )

            if thr_cluster is not None:
                t = thr[(thr["ClusterLabel"] == thr_cluster) & (thr["ë³€ìˆ˜"] == col)]
                if not t.empty and pd.notna(t.iloc[0]["ì„ê³„ê°’"]):
                    fig.add_hline(
                        y=float(t.iloc[0]["ì„ê³„ê°’"]), line_dash="dot", line_color="grey"
                    )

            # [ìˆ˜ì •] ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸
            fig.update_layout(
                margin=dict(l=40, r=20, t=40, b=40),
                xaxis_title=None,
                yaxis_title=col,
                hovermode="x unified",
                height=300,
            )

            # [ìˆ˜ì •] xì¶• ë²”ìœ„ ì„¤ì •
            # ì‚¬ìš©ìê°€ ì„ íƒí•œ ê¸°ê°„ì— ë§ì¶° xì¶• ë²”ìœ„ë¥¼ ë™ì ìœ¼ë¡œ ì„¤ì •
            x_range_start = pd.to_datetime(start_d)
            x_range_end = pd.to_datetime(end_d) + pd.Timedelta(days=1)
            fig.update_xaxes(range=[x_range_start, x_range_end], fixedrange=True)

            if not agg.empty:
                pad = (agg["Value"].max() - agg["Value"].min()) * 0.1
                fig.update_yaxes(
                    range=[agg["Value"].min() - pad, agg["Value"].max() + pad]
                )

            # [ìˆ˜ì •] st.plotly_chart í•¨ìˆ˜
            st.plotly_chart(
                fig,
                use_container_width=True,
                config={
                    "displayModeBar": False,
                    "scrollZoom": False,
                    "doubleClick": "reset",
                },
            )

with right:
    st.markdown("#### LOT ìƒì„¸ ì •ë³´")
    sel = st.session_state.get("selected_point")
    if not sel:
        st.info("ì°¨íŠ¸ì˜ ì (point)ì„ í´ë¦­í•˜ë©´ ìƒì„¸ ì •ë³´ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
    else:
        for key, value in sel.items():
            st.markdown(f"- **{key}**: {value}")

        if "Date" in sel and "Lot" in sel:
            sel_date_dt = pd.to_datetime(sel.get("Date")).date()
            info = lot_span[
                (lot_span["Date"] == sel_date_dt) & (lot_span["Lot"] == sel.get("Lot"))
            ]
            if not info.empty:
                st.markdown(
                    f"- **LOT êµ¬ê°„**: {info.iloc[0]['start']} ~ {info.iloc[0]['end']}"
                )

        st.button("ë‹«ê¸°", use_container_width=True, on_click=clear_selection)

# --- ì„±ëŠ¥ í‰ê°€ ì„¹ì…˜ ---
st.divider()
st.markdown("### ğŸ“Š ëª¨ë¸ ì˜ˆì¸¡ ì„±ëŠ¥ ì¢…í•©")


def display_performance_pie(pred_df, truth_df, title, colors):
    if truth_df.empty:
        return

    pred_df["Date"] = pd.to_datetime(pred_df["Date"]).dt.date
    truth_df["Date"] = pd.to_datetime(truth_df["Date"]).dt.date
    pred_df["Lot"] = pred_df["Lot"].astype(str)
    truth_df["Lot"] = truth_df["Lot"].astype(str)

    perf_df = pd.merge(pred_df, truth_df, on=["Date", "Lot"], how="inner")

    if perf_df.empty:
        st.warning(f"{title} ëª¨ë¸ì´ í‰ê°€í•  ì›ë³¸ LOT ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    total_lots = len(perf_df)
    perf_df["Correct"] = perf_df["PredCluster"] == perf_df["ClusterLabel"]
    correct_count = perf_df["Correct"].sum()
    accuracy = (correct_count / total_lots) * 100 if total_lots > 0 else 0
    counts = (
        perf_df["Correct"].value_counts().rename({True: "Correct", False: "Incorrect"})
    )

    col1, col2 = st.columns(2)
    with col1:
        st.metric(label=f"**{title} Accuracy**", value=f"{accuracy:.2f} %")
    with col2:
        st.metric(label="**Evaluated LOTs**", value=f"{total_lots} ê°œ")

    fig_perf = px.pie(
        values=counts.values,
        names=counts.index,
        hole=0.4,
        color=counts.index,
        color_discrete_map=colors,
        title=f"{title} ëª¨ë¸ ì„±ëŠ¥",
    )
    fig_perf.update_traces(
        textposition="outside",
        textinfo="percent+label",
        marker=dict(line=dict(color="#FFFFFF", width=2)),
    )
    fig_perf.update_layout(
        showlegend=False, margin=dict(t=40, b=20, l=20, r=20), height=300
    )
    st.plotly_chart(fig_perf, use_container_width=True)


c3, c4 = st.columns(2)
with c3:
    display_performance_pie(
        pred[pred["Source"] == "lgbm"].copy(),
        truth.copy(),
        "LGBM",
        {"Correct": "#1f77b4", "Incorrect": "#ff7f0e"},
    )
with c4:
    display_performance_pie(
        pred[pred["Source"] == "variance"].copy(),
        truth.copy(),
        "Variance",
        {"Correct": "#2ca02c", "Incorrect": "#d62728"},
    )
