import numpy as np
import pandas as pd
from sklearn.metrics import confusion_matrix, precision_recall_fscore_support
from sklearn.preprocessing import StandardScaler

df_mean = pd.read_csv("/Users/t2023-m0056/Desktop/á„‘á…¡á„‹á…µá†¯/df_mean (1).csv")
df_thresh_z = pd.read_csv("/Users/t2023-m0056/Desktop/á„‘á…¡á„‹á…µá†¯/df_thresh_z (1).csv")
# =========================================================
# 0) ì…ë ¥ ì „ì œ
# - df_mean: ['Date','Lot','ClusterLabel', ë³€ìˆ˜ë“¤...] (ClusterLabel: ì •ìƒ=0, ë¶ˆëŸ‰=1/2/3)
# - df_thresh_z: ['ClusterLabel','ë³€ìˆ˜','ì„ê³„ê°’'] (+ ì„ íƒ: 'direction' [+1/-1])
# =========================================================

# ---------------------------------------------------------
# 1) ì„¤ì • (ğŸš¨ ì´ ë¶€ë¶„ì˜ ì„ê³„ê°’ë§Œ ìˆ˜ì •í•˜ì„¸ìš”)
# ---------------------------------------------------------
RND_DECIMALS = 2
LOG_EPS = 1e-6
WINDOW_SIZE = 6

# SPC ë£°ì— ë¶€ì—¬í•  ê°€ì¤‘ì¹˜ ì„¤ì • (í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ê°€ì¤‘ì¹˜ë¥¼ ê·¸ëŒ€ë¡œ ì ìš©)
RULE_WEIGHTS = {
    "rule1": 5,
    "rule2": 4,
    "rule3": 3,
    "rule4": 2,
    "rule5": 2,
    "rule6": 2,
    "rule7": 1,
    "rule8": 1,
}

# â­ í•™ìŠµì„ í†µí•´ ì–»ì€ ìµœì  ì„ê³„ê°’ì„ ì—¬ê¸°ì— ì§ì ‘ ì…ë ¥í•©ë‹ˆë‹¤ â­
OPTIMAL_THRESHOLD_1 = 2.0  # ë³€ë™ì„± ë£° ëª¨ë¸ì˜ ìµœì  ì„ê³„ê°’ (ì˜ˆì‹œ)
OPTIMAL_THRESHOLD_2 = 7.0  # SPC ë£° ëª¨ë¸ì˜ ìµœì  ì„ê³„ê°’ (ì˜ˆì‹œ)


# ---------------------------------------------------------
# 2) ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬
# ---------------------------------------------------------
df_mean_sorted = df_mean.sort_values(["Date", "Lot"]).reset_index(drop=True)
df_thresh_z_binary = df_thresh_z[df_thresh_z["ClusterLabel"] > 0].copy()
if "direction" not in df_thresh_z_binary.columns:
    df_thresh_z_binary["direction"] = 1
df_thresh_z_binary["effective_threshold"] = (
    df_thresh_z_binary["ì„ê³„ê°’"] * df_thresh_z_binary["direction"]
)
df_thresh_binary_final = df_thresh_z_binary.loc[
    df_thresh_z_binary.groupby("ë³€ìˆ˜")["effective_threshold"].idxmin()
].reset_index(drop=True)
df_thresh_binary_final["ì„ê³„ê°’"] = df_thresh_binary_final["effective_threshold"]

vars_with_thresholds = sorted(
    set(df_thresh_binary_final["ë³€ìˆ˜"]).intersection(df_mean_sorted.columns)
)
if not vars_with_thresholds:
    raise ValueError(
        "ë³€ë™ì„±ë£°ì— ì‚¬ìš©í•  ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. 'df_thresh_z'ì™€ 'df_mean'ì˜ ë³€ìˆ˜ëª…ì„ í™•ì¸í•˜ì„¸ìš”."
    )

df_all = df_mean_sorted.copy()
y_true = (df_all["ClusterLabel"] > 0).astype(int)
grouped = df_all.groupby(["Date", "Lot"])

df_normal = df_all[df_all["ClusterLabel"] == 0]
normal_stats = df_normal[vars_with_thresholds].agg(["mean", "std"]).T
normal_stats.columns = ["mean", "std"]


# ---------------------------------------------------------
# 3) ëª¨ë¸ í•¨ìˆ˜ ì •ì˜
# ---------------------------------------------------------
def run_variance_rule_model(df, cluster_thr_df):
    scores = []
    for _, row in df.iterrows():
        cur_score = 0
        for _, t in cluster_thr_df.iterrows():
            var, thr, d = t["ë³€ìˆ˜"], t["ì„ê³„ê°’_tr"], t["direction"]
            if var in row.index and not pd.isna(row[var]) and not pd.isna(thr):
                if d * (row[var] - thr) > 0:
                    cur_score += 1
        scores.append(cur_score)
    return pd.Series(scores, index=df.index)


def run_spc_rule_model(df, vars_list, rule_weights, normal_stats):
    df_model_2 = df.copy()
    spc_scores = pd.DataFrame(
        np.zeros((len(df_model_2), len(vars_list))),
        index=df_model_2.index,
        columns=vars_list,
    )
    grouped = df_model_2.groupby(["Date", "Lot"])

    for var in vars_list:
        if var not in normal_stats.index:
            continue

        z_score = pd.Series(0.0, index=df_model_2.index)
        for _, group_df in grouped:
            if len(group_df) >= 2:
                ma = group_df[var].rolling(window=WINDOW_SIZE, min_periods=1).mean()
                std = group_df[var].rolling(window=WINDOW_SIZE, min_periods=1).std()
                group_z_score = (group_df[var] - ma) / std.replace(0, np.nan)
            else:
                mean = normal_stats.loc[var, "mean"]
                std = normal_stats.loc[var, "std"]
                group_z_score = (
                    (group_df[var] - mean) / std
                    if not pd.isna(std) and std != 0
                    else pd.Series(0.0, index=group_df.index)
                )
            z_score.loc[group_df.index] = group_z_score.fillna(0)

        spc_scores[var] += (np.abs(z_score) > 3).astype(int) * rule_weights["rule1"]
        spc_scores[var] += (
            ((np.abs(z_score.shift(1)) > 2) & (np.abs(z_score) > 2))
            | ((np.abs(z_score.shift(2)) > 2) & (np.abs(z_score) > 2))
        ).astype(int) * rule_weights["rule2"]
        spc_scores[var] += (
            (
                (np.abs(z_score.shift(1)) > 1)
                & (np.abs(z_score) > 1)
                & (np.abs(z_score.shift(2)) > 1)
                & (np.abs(z_score.shift(3)) > 1)
            )
            | (
                (np.abs(z_score.shift(2)) > 1)
                & (np.abs(z_score.shift(3)) > 1)
                & (np.abs(z_score.shift(4)) > 1)
                & (np.abs(z_score) > 1)
            )
        ).astype(int) * rule_weights["rule3"]

        # ğŸš¨ ì´ ë¶€ë¶„ì˜ ì½”ë“œê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.
        spc_scores[var] += (
            z_score.rolling(window=9, center=False)
            .apply(lambda x: 1 if (x > 0).all() or (x < 0).all() else 0, raw=True)
            .fillna(0)
            .astype(int)
            * rule_weights["rule4"]
        )
        spc_scores[var] += (
            z_score.rolling(window=6, center=False)
            .apply(
                lambda x: (
                    1
                    if (pd.Series(x).diff().dropna() > 0).all()
                    or (pd.Series(x).diff().dropna() < 0).all()
                    else 0
                ),
                raw=True,
            )
            .fillna(0)
            .astype(int)
            * rule_weights["rule5"]
        )
        spc_scores[var] += (
            z_score.rolling(window=14, center=False)
            .apply(
                lambda x: (
                    1
                    if (
                        np.sign(pd.Series(x).diff().dropna())[1:]
                        * np.sign(pd.Series(x).diff().dropna())[:-1]
                        < 0
                    ).all()
                    else 0
                ),
                raw=True,
            )
            .fillna(0)
            .astype(int)
            * rule_weights["rule6"]
        )
        spc_scores[var] += (
            z_score.rolling(window=15, center=False)
            .apply(lambda x: 1 if (pd.Series(x).abs() < 1).all() else 0, raw=True)
            .fillna(0)
            .astype(int)
            * rule_weights["rule7"]
        )
        spc_scores[var] += (
            z_score.rolling(window=8, center=False)
            .apply(lambda x: 1 if (pd.Series(x).abs() > 1).all() else 0, raw=True)
            .fillna(0)
            .astype(int)
            * rule_weights["rule8"]
        )

    return spc_scores.sum(axis=1)


# ---------------------------------------------------------
# 4) ê° ëª¨ë¸ ì‹¤í–‰ ë° ì˜ˆì¸¡ ì ìˆ˜ ìƒì„±
# ---------------------------------------------------------
# ëª¨ë¸ 1: ë³€ë™ì„± ë£°
df_all_scaled = df_all.copy()
transformers = {
    var: StandardScaler().fit(df_normal[[var]]) for var in vars_with_thresholds
}
df_thresh_tr = df_thresh_binary_final.copy()
df_thresh_tr["ì„ê³„ê°’_tr"] = df_thresh_tr.apply(
    lambda r: transformers[r["ë³€ìˆ˜"]].transform([[r["ì„ê³„ê°’"]]])[0][0], axis=1
)
cluster_thr_df = df_thresh_tr[["ë³€ìˆ˜", "ì„ê³„ê°’_tr", "direction"]].dropna(
    subset=["ì„ê³„ê°’_tr"]
)

for var in vars_with_thresholds:
    df_all_scaled[var] = transformers[var].transform(df_all_scaled[[var]])

score_model_1 = run_variance_rule_model(df_all_scaled, cluster_thr_df)

# ëª¨ë¸ 2: SPC ë£°
score_model_2 = run_spc_rule_model(
    df_all, vars_with_thresholds, RULE_WEIGHTS, normal_stats
)

# print(f"âœ”ï¸ ë³€ë™ì„± ë£° ëª¨ë¸ ìµœì  ì„ê³„ê°’: {OPTIMAL_THRESHOLD_1}")
# print(f"âœ”ï¸ SPC ë£° ëª¨ë¸ ìµœì  ì„ê³„ê°’: {OPTIMAL_THRESHOLD_2}")

# ---------------------------------------------------------
# 5) ì•™ìƒë¸”(íˆ¬í‘œ) ë° ìµœì¢… íŒì •
# ---------------------------------------------------------
predictions_df = pd.DataFrame(index=df_all.index)
# ì‚¬ì „ì— ì„¤ì •í•œ ìµœì  ì„ê³„ê°’ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡
predictions_df["pred_model_1"] = (score_model_1 >= OPTIMAL_THRESHOLD_1).astype(int)
predictions_df["pred_model_2"] = (score_model_2 >= OPTIMAL_THRESHOLD_2).astype(int)
predictions_df["vote_score"] = predictions_df[["pred_model_1", "pred_model_2"]].sum(
    axis=1
)

df_all["Final_Flag"] = "ì •ìƒ"
df_all.loc[predictions_df["vote_score"] == 1, "Final_Flag"] = "ê²½ê³ "
df_all.loc[predictions_df["vote_score"] >= 2, "Final_Flag"] = "ì¡°ì¹˜ í•„ìš”"

# print("\n=== ì•™ìƒë¸” ìµœì¢… íŒì • ê²°ê³¼(ìƒ˜í”Œ) ===")
# print(df_all[['Date','Lot','ClusterLabel','Final_Flag']].head(10))

# ---------------------------------------------------------
# 6) ìµœì¢… ì„±ëŠ¥ í‰ê°€
# ---------------------------------------------------------
y_pred_final = (predictions_df["vote_score"] >= 1).astype(int)
cm = confusion_matrix(y_true, y_pred_final, labels=[0, 1])
tn, fp, fn, tp = cm.ravel()
prec, rec, f1, _ = precision_recall_fscore_support(
    y_true, y_pred_final, average="binary", zero_division=0
)

# print("\n=== ì•™ìƒë¸” ìµœì¢… ì„±ëŠ¥ í‰ê°€ ===")
# print("\n=== Confusion Matrix (0:ì •ìƒ, 1:ë¶ˆëŸ‰) ===")
# print(pd.DataFrame(cm, index=['True_0','True_1'], columns=['Pred_0','Pred_1']))
# print(f"TN={tn} FP={fp} FN={fn} TP={tp}")
# print(f"Precision={prec:.3f} Recall={rec:.3f} F1={f1:.3f}")

# ===== LOT ë‹¨ìœ„ ì´ì§„ íŒì • ì €ì¥ =====
# row ë‹¨ìœ„ â†’ LOT ë‹¨ìœ„ë¡œ ì§‘ê³„ (í•œ ë²ˆì´ë¼ë„ 1ì´ë©´ LOT=1)
row_results = df_all[["Date", "Lot"]].copy()
row_results["PredFlag"] = y_pred_final.values  # 0/1 (vote_score>=1)

# LOTë³„ ì´ì§„ í”Œë˜ê·¸
lot_flag = row_results.groupby(["Date", "Lot"], as_index=False).agg(
    PredFlag=("PredFlag", "max")
)

# (ì„ íƒ) LOTë³„ ìµœëŒ€ ì ìˆ˜ë„ ê°™ì´ ì €ì¥í•˜ê³  ì‹¶ë‹¤ë©´:
lot_scores = pd.DataFrame(
    {
        "Date": df_all["Date"],
        "Lot": df_all["Lot"],
        "score_variance": score_model_1.values,
        "score_spc": score_model_2.values,
        "vote_score": predictions_df["vote_score"].values,
    }
)
lot_scores = lot_scores.groupby(["Date", "Lot"], as_index=False).agg(
    score_variance_max=("score_variance", "max"),
    score_spc_max=("score_spc", "max"),
    vote_score_max=("vote_score", "max"),
)

# ë³‘í•©(ì›í•˜ë©´ ë¹¼ë„ ë¨)
lot_out = lot_flag.merge(lot_scores, on=["Date", "Lot"], how="left")

# ë¬¸ìì—´ë¡œ ì €ì¥(ì•± í˜¸í™˜)
lot_out["Date"] = pd.to_datetime(lot_out["Date"]).dt.date.astype(str)
lot_out["Lot"] = lot_out["Lot"].astype(str)

# ì €ì¥
out_path = "pred_binary_lot.csv"
lot_out.to_csv(out_path, index=False)
print(f"âœ” saved: {out_path} ({lot_out.shape[0]} lots)")
